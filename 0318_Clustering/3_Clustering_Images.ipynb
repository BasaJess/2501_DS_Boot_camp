{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Clustering of Images\n",
    "\n",
    "Similar to texts you can also cluster images. For complex images it is usually necessary to use a convolutional neural network (CNN), like for example the model VGG16, as a feature extractor only, meaning that we will remove the final (prediction) layer so that we can obtain feature vectors of the images which then can be clustered.\n",
    "\n",
    "In our case we will use a simpler example. We will cluster the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cluster import DBSCAN, MiniBatchKMeans, KMeans, AgglomerativeClustering\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the digits dataset\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at how the digits look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting of the digit dataset\n",
    "def plot_digits(data):\n",
    "    fig, ax = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                           subplot_kw=dict(xticks=[], yticks=[]))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        im = axi.imshow(data[i].reshape(8, 8), cmap='binary')\n",
    "        im.set_clim(0, 16)\n",
    "plot_digits(digits.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can cluster the digits with a simple `KMeans` clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the KMeans model and predict digits\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "clusters = kmeans.fit_predict(digits.data)\n",
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result are 10 clusters in 64 dimensions. Notice that the cluster centers themselves are 64-dimensional points, and can themselves be interpreted as the \"typical\" digit within the cluster. Let's see what these cluster centers look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cluster centers\n",
    "fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n",
    "centers = kmeans.cluster_centers_.reshape(10, 8, 8)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even without the labels, KMeans is able to find clusters whose centers are recognizable digits, with perhaps the exception of 1 and 8.\n",
    "\n",
    "Because Kmeans is an unsupervised algorithm it doesn't know the correct labels but assigns them randomly. Before we can properly evaluate the performance of the algorithm we need to fix this and by matching each learned cluster label with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a labels array to match the learned cluster lables with the true labels\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(digits.target[mask])[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check how accurate our unsupervised clustering was in finding similar digits within the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusing matrix\n",
    "mat = confusion_matrix(digits.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=digits.target_names,\n",
    "            yticklabels=digits.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "\n",
    "print('Accuracy: ', accuracy_score(digits.target, labels))\n",
    "print('==============================================================')\n",
    "print(confusion_matrix(digits.target,labels))\n",
    "print('==============================================================')\n",
    "print(classification_report(digits.target,labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a simple `KMeans` algorithm we were able to correctly cluster **~79%** of the input digits. As we might expect from the visualization of the cluster centers, the main point of confusion was between the eights and ones. Nevertheless, it is still an impressive example of how we can build a digit classifier without a reference to any known label.\n",
    "\n",
    "Let's try to take this even further. We can use the **t-distributed stochastic neighbor embedding** (t-SNE) algorithm to preprocess the data before performing Kmeans. t-SNE is a nonlinear embedding algorithm that is particularly adept at preserving points within clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the data: this step will take several seconds\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
    "digits_proj = tsne.fit_transform(digits.data)\n",
    "\n",
    "# Compute the clusters\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "clusters = kmeans.fit_predict(digits_proj)\n",
    "\n",
    "# Permute the labels\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(digits.target[mask])[0]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "mat = confusion_matrix(digits.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=digits.target_names,\n",
    "            yticklabels=digits.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "\n",
    "# Compute the accuracy\n",
    "print('Accuracy: ', accuracy_score(digits.target, labels))\n",
    "print('==============================================================')\n",
    "print(confusion_matrix(digits.target, labels))\n",
    "print('==============================================================')\n",
    "print(classification_report(digits.target, labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we achieve **93% accuracy** without using the labels. This is the power of unsupervised learning when used carefully: it can extract information from the dataset that might be difficult to extract by hand or eye.\n",
    "\n",
    "Let's also try **DBSCAN**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the data: this step will take several seconds\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
    "digits_proj = tsne.fit_transform(digits.data)\n",
    "\n",
    "# Compute the clusters\n",
    "clustering = DBSCAN(eps=5, min_samples=15)\n",
    "clusters = clustering.fit_predict(digits_proj)\n",
    "\n",
    "# Permute the labels\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(digits.target[mask])[0]\n",
    "\n",
    "# Plotting the confusing matrix\n",
    "mat = confusion_matrix(digits.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=digits.target_names,\n",
    "            yticklabels=digits.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "\n",
    "# Compute the accuracy\n",
    "print('Accuracy: ', accuracy_score(digits.target, labels))\n",
    "print('==============================================================')\n",
    "print(confusion_matrix(digits.target, labels))\n",
    "print('==============================================================')\n",
    "print(classification_report(digits.target, labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting an **accuracy** of **79%** we can see that DBSCAN does not work as well as KMeans. Apparently the algorithm also struggled to correctly identify ones and nines."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "You can also cluster elements in one picture by grouping or aggregating the pixel values of an image into a certain number of natural classes (groups) based on statistical similarity. That can for example be used for color compression. Imagine you have an image with millions of colors. In most images, a large number of the colors will be unused, and many of the pixels in the image will have similar or even identical colors.\n",
    "\n",
    "In our example here we will use clustering to highlight particular landforms on satellite imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mc\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a satellite image of the Seville ([Source](http://www.esa.int/ESA_Multimedia/Missions/Sentinel-2/(sortBy)/published/(result_type)/images)). We will load the image with Rasterio, an open source python library that reads and writes raster datasets such as satellite imagery and terrain models in different formats like GEOTIFF and JP2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seville_raster = rio.open(\"images/Seville_Spain.jpg\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize this image nicely will need to adjust its contrast first by stretching it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seville_arr = seville_raster.read()\n",
    "vmin, vmax = np.nanpercentile(seville_arr, (5,95))  # 5-95% contrast stretch\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[20,20], ncols=1,nrows=1)\n",
    "show(seville_raster, cmap='gray', vmin=vmin, vmax=vmax, ax=ax)\n",
    "ax.set_axis_off()\n",
    "fig.savefig(\"images/seville_new.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print the shape of this image we will see that it has only the information for the height and width (height, width). Before we go on we need to change it to match the required shape of (height, width, channels). Channels in this case represent the color channels RGB (red, green, blue). \n",
    "We can reshape the image by creating an empty array using our image size, counts and data type from the meta data. With a for loop we can slice each channel/band and reform it in our empty array. At the end of the loop we will get a new array with the required shape that has the same size and number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the original image\n",
    "seville_raster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array with same dimension and data type\n",
    "imgxyb = np.empty((seville_raster.height, seville_raster.width, seville_raster.count), seville_raster.meta['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the raster's bands to fill the empty array\n",
    "for band in range(imgxyb.shape[2]):\n",
    "    imgxyb[:,:,band] = seville_raster.read(band+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgxyb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to train our model, but first, we need to combine our X (width) and Y (height) dimensions to 1 dimension, so that we have a 2d array instead of 3d. This array can be fed into a `KMeans` cluster model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 2d array\n",
    "img2d = imgxyb[:,:,:3].reshape((imgxyb.shape[0]*imgxyb.shape[1],imgxyb.shape[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: The most important parameter to set is the `n_clusters` which represents the number of clusters that we want to group our pixels into, we choose 4 classes for clarity, but you can choose as many classes as you can see in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the classifier and train it\n",
    "cl = KMeans(n_clusters=4)\n",
    "param = cl.fit(img2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels of the classes and reshape it x-y-bands shape order (one band only)\n",
    "img_cl = cl.labels_\n",
    "img_cl = img_cl.reshape(imgxyb[:,:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cl.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the resulting image, we use a custom color map where you can control the color of each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom color map to represent our 4 different classes\n",
    "cmap = mc.LinearSegmentedColormap.from_list(\"\", [\"#B90E0A\",\"navy\",\"green\",\"#E1AD01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the resulting array and save it as jpg image\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(img_cl, cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"images/seville_clustered.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try the code with other pictures. (Maybe try the code with a selfie with different colors and number of clusters... ;))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
