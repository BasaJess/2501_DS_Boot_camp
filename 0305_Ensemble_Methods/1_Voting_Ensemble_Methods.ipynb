{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Methods\n",
    "\n",
    "**The code is included here as an example for you to refer to for your future projects.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RSEED=42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import diabetes data\n",
    "df = pd.read_csv('data/pima-native-americans-diabetes.csv', header=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target and split into train and test set\n",
    "y = df[8]\n",
    "X = df.drop(8, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = LogisticRegression(random_state = RSEED)\n",
    "model2 =  KNeighborsClassifier()\n",
    "model3 = DecisionTreeClassifier(random_state = RSEED)\n",
    "\n",
    "model = VotingClassifier(estimators = [('lr', model1), ('knn', model2), ('dt', model3)], voting = 'hard')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(random_state = RSEED)\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = DecisionTreeClassifier(random_state = RSEED)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(X_test)\n",
    "pred2 = model2.predict_proba(X_test)\n",
    "pred3 = model3.predict_proba(X_test)\n",
    "\n",
    "finalpred = (pred1 + pred2 + pred3) / 3\n",
    "finalpred = np.argmax(finalpred.round(0), axis = 1)\n",
    "(y_test == finalpred).sum() / len(finalpred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(random_state = RSEED)\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = DecisionTreeClassifier(random_state = RSEED)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(X_test)\n",
    "pred2 = model2.predict_proba(X_test)\n",
    "pred3 = model3.predict_proba(X_test)\n",
    "\n",
    "acc1 = accuracy_score(y_train, model1.predict(X_train))\n",
    "acc2 = accuracy_score(y_train, model2.predict(X_train))\n",
    "acc3 = accuracy_score(y_train, model3.predict(X_train))\n",
    "\n",
    "acc_sum = acc1 + acc2 + acc3\n",
    "\n",
    "weight1 = acc1/acc_sum\n",
    "weight2 = acc2/acc_sum\n",
    "weight3 = acc3/acc_sum\n",
    "\n",
    "finalpred = (pred1*weight1 + pred2*weight2 + pred3*weight3)\n",
    "finalpred = np.argmax(finalpred.round(0), axis = 1)\n",
    "(y_test == finalpred).sum() / len(finalpred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Stacking in Scikit-Learn\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier(random_state = RSEED)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('rf', RandomForestClassifier(random_state = RSEED))\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression())\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify the example above, the stacking model we have created has only two levels. The **DecisionTree, KNN and RandomForest** models are built at **level zero**, while a **LogisticRegression** model is built at **level one**.\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifier explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking without `StackingClassifier`\n",
    "\n",
    "We take 3 base classifiers and one final estimator separately. Initialize the object for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Estimators\n",
    "dt = DecisionTreeClassifier(random_state = RSEED)\n",
    "knn = KNeighborsClassifier()\n",
    "rf = RandomForestClassifier(random_state = RSEED)\n",
    "\n",
    "# final estimator\n",
    "final_est = LogisticRegression()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stacking classification we divide our train dataset into two parts\n",
    "1. With the first part, we train our base estimators  \n",
    "2. And with the second part we predict probabilities from base estimator and train the final estimator on the probabilities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_train, y_train, stratify=y_train, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all the base estimators on the 1st half of the train dataset\n",
    "dt_model = dt.fit(X_train_1, y_train_1)\n",
    "knn_model = knn.fit(X_train_1, y_train_1)\n",
    "rf_model = rf.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Then with the second half of the train dataset we predict the probabilities from the base estimators\n",
    "dt_probab = dt_model.predict_proba(X_train_2)[:,1]\n",
    "knn_probab = knn_model.predict_proba(X_train_2)[:,1]\n",
    "rf_probab = rf_model.predict_proba(X_train_2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we combine all the probabilities and form a training data (probabilities) for the final estimator\n",
    "lr_X = pd.concat([\n",
    "            pd.DataFrame(dt_probab), \n",
    "            pd.DataFrame(knn_probab),\n",
    "            pd.DataFrame(rf_probab),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final estimator on the combined probabilities and target values\n",
    "final_est.fit(lr_X, y_train_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test dataset, we do the same thing as while training\n",
    "1. predict probabilities from base estimators on the test dataset\n",
    "2. combine the probabilities from base estimator to form a test dataset for final estimator\n",
    "3. predict with final estimator on test data (probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred = dt_model.predict_proba(X_test)[:,1]\n",
    "knn_pred = knn_model.predict_proba(X_test)[:,1]\n",
    "rf_pred = rf_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "comb_pred = pd.concat([\n",
    "            pd.DataFrame(dt_pred), \n",
    "            pd.DataFrame(knn_pred),\n",
    "            pd.DataFrame(rf_pred),\n",
    "        ], axis=1)\n",
    "\n",
    "pred_final = final_est.predict(comb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "\n",
    "print(accuracy_score(y_test, pred_final))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "17fc12523d787057f7a889e7d833c83e2ff8127049b3dfb830fea057b3e5fb02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
