{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9HmC2T4ld5B"
   },
   "source": [
    "# Overfit and Underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already learned about overfitting and underfitting in the context of machine learning algorithms. Unfortunately, these topics are also important when it comes to training an artificial neural network.\n",
    "\n",
    "You may have observed in previous notebooks that the accuracy(/mae) of your model on the validation set reaches a peak(/minimum) after training for a number of epochs and then stagnates or, worse, starts to decrease(/increase). This is a clear sign that the model is overfitting the training data. \n",
    "\n",
    "Artificial neural networks tend to overfit the data. It is possible to achieve extremely high accuracy (or low mae) on your training data if you just train your model long enough. However, this is not desirable because these models do not generalize well and will perform poorly on a test set or new data.\n",
    "\n",
    "Underfitting is another problem. If your model is not powerful enough, it is over-regularized, or it has not been trained long enough, it may perform poorly on the training and test set because it has not been able to learn the relevant features from the data.\n",
    "\n",
    "The best way to prevent your model from overfitting is using a dataset for training that covers the full range of inputs that the model is expected to handle. Additional data may only be useful if it covers new and interesting cases.\n",
    "\n",
    "However, sometimes you will need to use different regularization techniques to counteract the overfitting of the data. In this notebook we will explore some common techniques that can help you with this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At the end of the notebooks you should: \n",
    "\n",
    "* know different strategies to tackle overfitting\n",
    "* know how to apply L1 or L2 regularization\n",
    "* know what `dropout layers` are and how to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL8UoOTmGGsL"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FklhSI0Gg9R"
   },
   "source": [
    "Before getting started, import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pZ8A2liqvgk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnAtAjqRYVXe"
   },
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seeds etc.\n",
    "RSEED = 42\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cweoTiruj8O"
   },
   "source": [
    "## The Boston Housing data set\n",
    "\n",
    "We will use the boston housing data set in this notebook. You can find it in the data folder in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from data folder\n",
    "df = pd.read_csv('../data/boston.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missings\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and remove from df \n",
    "target = df.pop(\"MEDV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical values\n",
    "col_scale = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'LSTAT']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[col_scale] = scaler.fit_transform(X_train[col_scale])\n",
    "X_test[col_scale] = scaler.transform(X_test[col_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to np array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexity\n",
    "\n",
    "One way to counteract under- or overfitting without using any regularization technique is to adapt the model complexity. The larger your neural network is the easier it is to overfit the data. \n",
    "\n",
    "Unfortunately, there is no magical formula to determine the right size or architecture of your model (in terms of the number of layers, or the right size for each layer). You will have to experiment using a series of different architectures.\n",
    "To find an appropriate model size, it's best to start with relatively few layers and parameters, then begin increasing the size of the layers or adding new layers until the validation loss gets worse.\n",
    "\n",
    "In this notebook we will train three different models with varying complexity on the Boston housing data set and compare their performance. The results will be stored in a dictionary and the following plotting functions will help us to visualize the performance.\n",
    "We will also define the optimizer we want to use as well as a [learning rate decay](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay). Many models train better with a gradually decreasing learning rate during training.\n",
    "The `optimizers.schedule` helps us to reduce the learning rate over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store results\n",
    "training_history = {}\n",
    "\n",
    "# Define number of epochs and learning rate decay\n",
    "N_TRAIN = len(X_train)\n",
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.01,\n",
    "    decay_steps=STEPS_PER_EPOCH*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "\n",
    "\n",
    "# Define optimizer used for modelling\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule, name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for MSE\n",
    "def plot_metric(history):\n",
    "    plt.plot(history.history['mse'])\n",
    "    plt.plot(history.history['val_mse'])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for loss\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small model\n",
    "\n",
    "We'll start with a rather small model with two hidden layers and 32 units.\n",
    "\n",
    "The following function contains our models architecture (the number of layers and units) as well as information about the optimizer, loss and metric we use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture in function\n",
    "def get_compiled_small_model():\n",
    "    small_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(32,kernel_initializer = 'uniform', activation='relu', input_dim = 12),\n",
    "      tf.keras.layers.Dense(32,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    small_model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    return small_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate small model and print model summary\n",
    "with tf.device('/cpu:0'):\n",
    "    small_model = get_compiled_small_model()\n",
    "    print(small_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    training_history['small'] = small_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the progress that our model makes during the training process by plotting the MSE on the training and validation set against the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE history \n",
    "plot_metric(training_history['small'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same works for the loss. We can also visualize how the loss improved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss history\n",
    "plot_loss(training_history['small'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to evaluate the performance of our model on unseen data we can use the hold out test set we put aside at the beginning of the modelinng part. Its possible to evaluate the model performance using `.evaluate` or make predictions via `.predict` and calculate the MSE using sklearn's implemenatation `mean_squared_error`. Both should return the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the small model on test set using .evaluate\n",
    "loss, mse = small_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model MSE: {mse}')\n",
    "print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = small_model.predict(X_test)\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoints during training\n",
    "\n",
    "Training a articfical neural network can sometimes take a lot of time. Luckily, the `tf.keras.callbacks.ModelCheckpoin` callback allows you to continually save the model both during and at the end of training.\n",
    "So you can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted.\n",
    "\n",
    "#### Checkpoint callback usage\n",
    "We will create a `tf.keras.callbacks.ModelCheckpoint` callback that saves weights only during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where checkpoints should be stored\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0) # Set verbose != 0 if you want output during training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Model\n",
    "\n",
    "We can increase the complexity of our model by adding another hidden layer and increasing the number of units to 64. \n",
    "The steps for compiling the model and training it remain the same but this time we will add the prior defined callback when we fit our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for medium model architecture \n",
    "def get_compiled_medium_model():\n",
    "    medium_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu', input_dim = 12),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    medium_model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    return medium_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of medium sized model\n",
    "with tf.device('/cpu:0'):\n",
    "    medium_model = get_compiled_medium_model()\n",
    "    print(medium_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the medium model with the new callback\n",
    "with tf.device('/cpu:0'):\n",
    "    training_history['medium'] = medium_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0, \n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[cp_callback])  # Pass callback to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE with medium model\n",
    "plot_metric(training_history['medium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss with medium model\n",
    "plot_loss(training_history['medium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the medium model on test set using .evaluate\n",
    "loss, mse = medium_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Model\n",
    "\n",
    "Let's further increase the architecture of our model. We'll add another layer and increase the amount of units to 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for large model architecture \n",
    "def get_compiled_large_model():\n",
    "    large_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 12),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    large_model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    return large_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of large sized model\n",
    "with tf.device('/cpu:0'):\n",
    "    large_model = get_compiled_large_model()\n",
    "    print(large_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the new callback\n",
    "with tf.device('/cpu:0'):\n",
    "    training_history['large'] = large_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE with large model\n",
    "plot_metric(training_history['large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss with large model\n",
    "plot_loss(training_history['large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the large model on test set using .evaluate\n",
    "loss, mse = large_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies to prevent overfitting\n",
    "\n",
    "### Regularization \n",
    "\n",
    "You may be familiar with Occam's Razor principle: given two explanations for something, the explanation most likely to be correct is the \"simplest\" one, the one that makes the least amount of assumptions. This also applies to the models learned by neural networks: given some training data and a network architecture, there are multiple sets of weights values (multiple models) that could explain the data, and simpler models are less likely to overfit than complex ones.\n",
    "\n",
    "In the next section we will try out one form of **regularization**. Hopefully, you all are familiar with L1 and L2 regularization as we talked about it several times during the bootcamp. Nevertheless, let's refresh the general concepts before we move on: \n",
    "\n",
    "We can apply regularization techniques in order generate a simpler model to prevent overfitting. A \"simple model\" in this context is a model where the distribution of parameter values has less entropy (or a model with fewer parameters altogether). Thus a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights only to take small values, which makes the distribution of weight values more \"regular\". It is done by adding to the loss function of the network a cost associated with having large weights. This cost comes in two flavors:\n",
    "\n",
    "* [L1 regularization](https://developers.google.com/machine-learning/glossary/#L1_regularization), where the cost added is proportional to the absolute value of the weights coefficients (i.e. to what is called the \"L1 norm\" of the weights).\n",
    "\n",
    "* [L2 regularization](https://developers.google.com/machine-learning/glossary/#L2_regularization), where the cost added is proportional to the square of the value of the weights coefficients (i.e. to what is called the squared \"L2 norm\" of the weights). L2 regularization is also called weight decay in the context of neural networks. Don't let the different name confuse you: weight decay is mathematically the exact same as L2 regularization.\n",
    "\n",
    "L1 regularization pushes weights towards exactly zero encouraging a sparse model. L2 regularization will penalize the weights parameters without making them sparse since the penalty goes to zero for small weights - one reason why L2 is more common.\n",
    "\n",
    "In `tf.keras`, weight regularization is added by passing weight regularizer instances to layers as keyword arguments. Let's add L2 weight regularization to our large model from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large model with additional L2 regularization\n",
    "def get_compiled_l2_model():\n",
    "    l2_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                            input_dim = 12),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    l2_model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    return l2_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUUHoXb7w-_C"
   },
   "source": [
    "`l2(0.01)` means that every coefficient in the weight matrix of the layer will add `0.01 * weight_coefficient_value**2` to the total **loss** of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of model architecture\n",
    "with tf.device('/cpu:0'):\n",
    "    l2_model = get_compiled_l2_model()\n",
    "    print(l2_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regularized model\n",
    "with tf.device('/cpu:0'):\n",
    "    training_history['l2'] = l2_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,                                      \n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE with l2 model\n",
    "plot_metric(training_history['l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss with l2 model\n",
    "plot_loss(training_history['l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the regularized model\n",
    "loss, mse = l2_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the \"L2\" regularized model is now much more competitive with the the \"Medium\" model. This \"L2\" model is also much more resistant to overfitting than the \"Big\" model it was based on despite having the same number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Dropout is one of the most effective and most commonly used regularization techniques for neural networks, developed by Hinton and his students at the University of Toronto.\n",
    "\n",
    "The intuitive explanation for dropout is that because individual nodes in the network cannot rely on the output of the others, each node must output features that are useful on their own.\n",
    "\n",
    "Dropout, applied to a layer, consists of randomly \"dropping out\" (i.e. set to zero) a number of output features of the layer during training. Let's say a given layer would normally have returned a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input sample during training; after applying dropout, this vector will have a few zero entries distributed at random, e.g. [0, 0.5, 1.3, 0, 1.1].\n",
    "\n",
    "The \"dropout rate\" is the fraction of the features that are being zeroed-out; it is usually set between 0.2 and 0.5. At test time, no units are dropped out, and instead the layer's output values are scaled down by a factor equal to the dropout rate, so as to balance for the fact that more units are active than at training time.\n",
    "\n",
    "In `tf.keras` you can introduce dropout in a network via the Dropout layer, which gets applied to the output of layer right before.\n",
    "\n",
    "Let's add a Dropout layer after each dense layer in our network to see how they influence our models performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large model with additional dropout layer\n",
    "def get_compiled_dropout_model():\n",
    "    dropout_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 12),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    dropout_model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    return dropout_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of model architecture\n",
    "with tf.device('/cpu:0'):\n",
    "    dropout_model = get_compiled_dropout_model()\n",
    "    print(dropout_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dropout model\n",
    "with tf.device('/cpu:0'):\n",
    "    training_history['dropout'] = dropout_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE with dropout model\n",
    "plot_metric(training_history['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss with dropout model\n",
    "plot_loss(training_history['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the dropout model\n",
    "loss, mse = dropout_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine L2 and Dropout\n",
    "\n",
    "It's also possible and common to combine differnt regularisation techniques in one model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large model with additional dropout layer and L2 regularization\n",
    "def get_compiled_l2_dropout_model():\n",
    "    l2_dropout_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                            input_dim = 12),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    l2_dropout_model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    return l2_dropout_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of model architecture\n",
    "with tf.device('/cpu:0'):\n",
    "    l2_dropout_model = get_compiled_l2_dropout_model()\n",
    "    print(l2_dropout_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "with tf.device('/cpu:0'):\n",
    "    training_history['l2_dropout'] = l2_dropout_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE with dropout and l2 model\n",
    "plot_metric(training_history['l2_dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss with dropout and l2 model\n",
    "plot_loss(training_history['l2_dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the dropout-l2 model\n",
    "loss, mse = l2_dropout_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "We can use the `tfdocs.plots.HistoryPlotter` to plot and compare all the results of our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate HistoryPlotter\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mse', smoothing_std=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results of all models\n",
    "plotter.plot(training_history)\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "plt.ylim([0, 50])\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Comparison of all models')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see that the large model without any regularization and the same model with L2 regularization achieved the best perfomance on the train as well as validation set. \n",
    "Their performance on the test set is also better than the one of the other models we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Large Model loss and MSE:')\n",
    "loss_large, mse_large = large_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('----'*10)\n",
    "print('L2 Model loss and MSE:')\n",
    "loss_l2, mse_l2 = l2_model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "As we can see from our models above, the Boston housing data set is not the best choice when it comes to demonstrate overfitting. All the models are only starting to overfit the data (more or less) after training for quite some time. We can easly restrict the number of epochs to generate proper results. Nevertheless, in this notebook you have learnt some important techniques to regularize your models. \n",
    "\n",
    "Let's recap: here are the most common ways to prevent overfitting in neural networks:\n",
    "\n",
    "* Get more training data.\n",
    "* Reduce the capacity of the network.\n",
    "* Add weight regularization.\n",
    "* Add dropout.\n",
    "\n",
    "Two important approaches not covered in this guide are:\n",
    "\n",
    "* data-augmentation\n",
    "* batch normalization\n",
    "\n",
    "Remember that each method can help on its own, but often combining them can be even more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our model\n",
    "\n",
    "Call `model.save` to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code. (Custom objects (e.g. subclassed models or layers) require special attention when saving and loading.) Since the optimizer-state is recovered, you can resume training from exactly where you left off.\n",
    "\n",
    "An entire model can be saved in two different file formats (`SavedModel` and `HDF5`). The TensorFlow `SavedModel` format is the default file format in TF2.x. However, models can be saved in `HDF5` format, too.\n",
    "\n",
    "Saving a fully-functional model is very useful—you can load them in TensorFlow.js (Saved Model, HDF5) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (SavedModel, HDF5)\n",
    "\n",
    "Let's have a look on how you can save your model useing `SaveModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SavedModel format\n",
    "\n",
    "The `SavedModel` format is another way to serialize models. Models saved in this format can be restored using `tf.keras.models.load_mode` and are compatible with TensorFlow Serving.\n",
    "\n",
    "In the next cell we will save our small model in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire small model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "large_model.save('saved_model/my_large_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see how you can load the model in order to make predictions, have a look at the next notebook..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "overfit_and_underfit.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
