{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitation of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is short but will hopefully highlight the limitations of linear regression. A linear regression model is only able to identify **linear** relationships. \n",
    "We can use the famous [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) dataset to show that linear regression can return the same results for very different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:47:51.075402Z",
     "start_time": "2020-05-04T12:47:49.531811Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Anscombe Quartet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:47:51.098614Z",
     "start_time": "2020-05-04T12:47:51.079289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Anscombe dataset includes 4 different data sets\n",
    "anscombe = sns.load_dataset(\"anscombe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:47:51.164417Z",
     "start_time": "2020-05-04T12:47:51.100992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the descriptive statistics for each dataset\n",
    "anscombe.groupby('dataset').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the table above, all four datasets have very similar descriptive statistics. If we were to look only at this summary, we might incorrectly assume that the datasets also look quite similar.\n",
    "Let's now calculate some summary statistics to plot the data with their regression lines.\n",
    "An easy way to calculate a linear least-squares regression and return the interesting statistics is to use the `.linregress()` function from the `scipy.stats` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:47:51.181781Z",
     "start_time": "2020-05-04T12:47:51.171536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function using linregress of stats module \n",
    "# for building a linear regression model for each dataset\n",
    "# Returns summary statistics\n",
    "def get_summarystats(dataset):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x=anscombe[anscombe.dataset==dataset].x,\n",
    "                                                               y=anscombe[anscombe.dataset==dataset].y)\n",
    "    \n",
    "    \n",
    "    return slope, intercept, r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:47:51.204561Z",
     "start_time": "2020-05-04T12:47:51.186127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting summary statistics for each dataset\n",
    "results = []\n",
    "for dataset in 'I II III IV'.split():\n",
    "    slope, intercept, r_value, p_value, std_err = get_summarystats(dataset)\n",
    "    results.append([slope, intercept, r_value])\n",
    "\n",
    "print('[slope, intercept, r_value] for each dataset')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression parameters are also almost identical. However, the datasets look significantly different when we plot them with their regression lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:47:52.022446Z",
     "start_time": "2020-05-04T12:47:51.221011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the results of a linear regression within each dataset\n",
    "sns.lmplot(x=\"x\", y=\"y\", col=\"dataset\", hue=\"dataset\", data=anscombe,\n",
    "            col_wrap=2, ci=None, palette='muted', height=4, scatter_kws={\"s\": 50, \"alpha\": 1});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From the diagrams above it is obvious that the fitted lines are basically identical - even though we have completely different data.  \n",
    "In these cases, it is intentionally obvious that the model is having trouble fitting lines to data sets II, III, and IV. Usually it is necessary to look at the plot of the residuals to see these errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Plots\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real data science project it is not enough to summarize the quality of your model in one value (like r-squared, RMSE...), you need to dig deeper and find out if the errors follow certain patterns. \n",
    "A common way to analyze this is to create so-called **Residual Plots**. These plots show - as the name suggests - the distribution of the residuals of your model. They are an essential part of any error analysis in regression problems!\n",
    "\n",
    "We can create residual plots for each dataset with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function which calculates residuals and plots them\n",
    "def get_residuals(dataset, color):\n",
    "    # store true y values\n",
    "    obs_values = anscombe[anscombe.dataset==dataset].y \n",
    "    # store predicted y values\n",
    "    pred_values = get_summarystats(dataset)[0] * anscombe[anscombe.dataset==dataset].x + get_summarystats(dataset)[1] \n",
    "    # calculate residuals\n",
    "    residuals = obs_values - pred_values\n",
    "    # plot residuals\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.scatter(anscombe[anscombe.dataset==dataset].x, residuals, color=color)\n",
    "    ax.set_ylabel(\"Residuals\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    fig.suptitle('Residual Scatter Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define same color palette as above\n",
    "color = sns.color_palette('muted')\n",
    "\n",
    "# Use defined function to plot residuals for all datasets\n",
    "for dataset, c in zip('I II III IV'.split(), color):\n",
    "    get_residuals(dataset, c) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a well-fitted model, the residuals are randomly distributed.  In our case, this is only true for data set I. For rather poorly fitted models, you will find patterns in your residual distribution as we can see for datasets II, III and IV. These patterns show us that our model is missing additional explanatory factors.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you want to learn more about residuals/residual plots at some point, you can start with these articles:\n",
    "\n",
    "* [What are residuals in statistics?](https://www.statology.org/residuals/) \n",
    "* [How to use residuals for regression model validation?](https://towardsdatascience.com/how-to-use-residual-plots-for-regression-model-validation-c3c70e8ab378)\n",
    "* [Interpreting residual plots to improve your regression](https://www.qualtrics.com/support/stats-iq/analyses/regression-guides/interpreting-residual-plots-improve-regression/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.linear_reg': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ef12b08bb6c784af5c9367ea3a2efc7622a4b1ab96569344e4e4dfe000de2265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
