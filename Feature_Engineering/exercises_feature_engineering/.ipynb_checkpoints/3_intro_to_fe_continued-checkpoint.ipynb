{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d145d3f5",
   "metadata": {},
   "source": [
    "# Feature Engineering Intro II\n",
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47b9c9-3fc6-4c7b-99fc-a358bbbeae33",
   "metadata": {},
   "source": [
    "- This notebook suppliments and serves as a continuation of notebook *1_intro_to fe*.\n",
    "- The reader is expected to run the codes and try to understand the concepts\n",
    "- The reader is expected to read the documentation pages that could be accessed via click, whenever possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60e499",
   "metadata": {},
   "source": [
    "#### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9f80539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization stack\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997025c0",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bdaaf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/penguins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4b01f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4933ef40-2037-4571-bd5a-1a9dfa7ec251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef96c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.25, random_state=42)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc3d77",
   "metadata": {},
   "source": [
    "#### features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2ff7b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'bill_length_mm',\n",
    "    'bill_depth_mm',\n",
    "    'flipper_length_mm'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'species',\n",
    "    'island',\n",
    "    'sex'\n",
    "]\n",
    "\n",
    "features = numerical_features + categorical_features\n",
    "\n",
    "target_variable = 'body_mass_g'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528dc7aa-8d1f-4060-8fca-e6b49a9f84f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### feature-target separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9b785ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature matrix and target column\n",
    "X_train, y_train = train[features], train[target_variable]\n",
    "X_test, y_test = test[features], test[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13261ea3-cf9c-43bb-b6bf-58c293ad7be3",
   "metadata": {},
   "source": [
    "- **Did you notice the order of feature-target separation and train-test split?**\n",
    "- **How is it different from what was done in previous notebooks?**\n",
    "- **Could you think about scenarious where it would be better one way or the other?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530645b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c201c5",
   "metadata": {},
   "source": [
    "## 1. Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eeebbd-a5b6-44ca-b602-10b5cca6aab0",
   "metadata": {},
   "source": [
    "#### 1.1 [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40917a9f-899b-4e66-acdf-3e265f9044e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **discussed in notebook *1_intro_to_fe***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a6a15-82b0-47d4-bf7f-c2b03819254d",
   "metadata": {},
   "source": [
    "#### 1.2 [`KNNImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)\n",
    "\n",
    "- Imputation for completing missing values using k-Nearest Neighbors.\n",
    "- Each sample's missing values are imputed using the mean value from `n` nearest neighbors found in the training set\n",
    "- Two samples are close if the features that neither is missing are close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba264232-528b-4bc7-bb5e-d963a0cb4ef2",
   "metadata": {},
   "source": [
    "**example: impute `bill_depth_mm`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66165f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "703dd822-97a4-4ab3-a4f7-fe1d29dab6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "knn_imputer.fit(X_train[['bill_depth_mm']])\n",
    "\n",
    "X_train['bill_depth_mm'] = knn_imputer.transform(\n",
    "    X_train[['bill_depth_mm']]\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5fb54eda-d7fe-4f89-9923-6804494cc4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a366db-7191-4d58-bf43-ed1839975e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbeef8-a852-4404-b818-96af8e762714",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f683a3",
   "metadata": {},
   "source": [
    "### 2. Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711fe22-1b5f-4076-a4eb-e33604010c1c",
   "metadata": {},
   "source": [
    "#### 2.1 [`get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "- Converts categorical variable into dummy/indicator variables.\n",
    "- Each variable is converted in as many 0/1 variables as there are different values.\n",
    "- Columns in the output are each named after a value; if the input is a DataFrame, the name of the original variable is prepended to the value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3376e-c736-4e80-ae43-6b4ce5fdc906",
   "metadata": {},
   "source": [
    "**example: create dummies for `species`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbaff3-0077-41fe-9747-1383c54161c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_species = pd.get_dummies(\n",
    "    data=X_train['species'],\n",
    "    drop_first=False,\n",
    ")\n",
    "dummy_species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f04f29",
   "metadata": {},
   "source": [
    "## is it not a problem to join without id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7937422-633b-46b0-a773-85bb330b0d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no Problem when indexes align correctly between the original DataFrame (X_train) and the dummy variables (dummy_species).\n",
    "# since dummy_species originally from X_train\n",
    "X_train.join(dummy_species).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd3eca-72fc-456f-b97e-0c3467c3a0d9",
   "metadata": {},
   "source": [
    "#### 2.2 [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e0a2c-3f4f-4e8e-9f80-d17b48498bf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **discussed in notebook *1_intro_to_fe***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22df328-46fa-4977-be9f-ebb1e430d62c",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4383a-7a8c-4f5f-90b4-9f08d3339fa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab53fa1-7ab6-4f26-9c75-89ad52adfbb2",
   "metadata": {},
   "source": [
    "### 3.1 Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54bfca-d101-49bc-b7b8-6ea305e0824c",
   "metadata": {},
   "source": [
    "- **discussed in notebook *1_intro_to_fe***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01118199-0c25-4a6a-9422-0bf4e94dcac9",
   "metadata": {},
   "source": [
    "### 3.2 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295fb21-ccfd-4a13-b6fc-30de2f12830f",
   "metadata": {},
   "source": [
    "- scikit-learn equivalent MinMaxScaler()\n",
    "- output range is always [0,1]\n",
    "- doesn't deal well with outliers\n",
    "- transformation formula:\n",
    ">$$z=\\dfrac{x - min(x)}{max(x) - min(x)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fca68d-95d1-4c13-adf1-bd32182d8ad5",
   "metadata": {},
   "source": [
    "**example: create normalized numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88387053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(series):\n",
    "    \"\"\"\n",
    "    Returns the normalized counterpart of a series.\n",
    "    The formula used is: (value - min) / (max - min), which scales the values between 0 and 1.\n",
    "    \"\"\"\n",
    "    min_ = series.min()  # Get the minimum value of the series\n",
    "    max_ = series.max()  # Get the maximum value of the series\n",
    "    return min_, max_, (series - min_) / (max_ - min_)  # Return min, max, and the normalized series\n",
    "\n",
    "# Create an empty DataFrame to hold the normalized features\n",
    "df_normal = pd.DataFrame()\n",
    "\n",
    "# Iterate over each feature in numerical_features for normalization\n",
    "for feature in numerical_features: \n",
    "    # Normalize the feature and get the min, max, and scaled values\n",
    "    min_, max_, t = normalize(X_train[feature])\n",
    "    \n",
    "    # Store the min and max values for each feature using dynamic variable names\n",
    "    vars()['min_' + feature] = min_\n",
    "    vars()['max_' + feature] = max_\n",
    "    \n",
    "    # Add the normalized feature to the new DataFrame with a '_scaled' suffix\n",
    "    df_normal[feature + '_scaled'] = t\n",
    "df_normal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01484e1a-5109-4102-92b1-218af895b1a2",
   "metadata": {},
   "source": [
    "#### [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5e036-e5f6-4bd4-915b-776a162aad3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Initialize the MinMaxScaler: \n",
    "# # By default, it scales the features to the range [0, 1]. If you want to scale to a different range, you can pass feature_range=(min, max) to the scaler.\n",
    "mm_scaler = MinMaxScaler() # 0 bis 1\n",
    "\n",
    "# Step 2: The fit() method calculates the minimum and maximum values for each feature in X_train[numerical_features]. \n",
    "# This information will be used to transform the data into the desired range.\n",
    "mm_scaler.fit(X_train[numerical_features])\n",
    "\n",
    "# Step 3: After fitting, the transform() method scales the data based on the previously calculated min and max values.\n",
    "# Each feature is transformed using the formula:\n",
    "t = mm_scaler.transform(X_train[numerical_features])\n",
    "\n",
    "# Step 4: Convert the transformed (scaled) data back into a DataFrame\n",
    "# Each transformed feature will have a '_mm_scaled' suffix to indicate scaling\n",
    "pd.DataFrame(t, columns=[f + '_mm_scaled' for f in numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d94e0-e830-4ac8-b4bf-f4fa5803cd3e",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3082a3cd-4572-48f8-b847-033778a57fe7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Feature Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e918e7-ee15-4b07-b911-b13083faeb0a",
   "metadata": {},
   "source": [
    "- **discussed in notebook *1_intro_to_fe***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3677191-c14e-4694-b19a-b3abaea1eb65",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4d681-2912-4b0a-8355-3b9a7e3967bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da89b3-6af9-4b07-966f-00020b4f6188",
   "metadata": {},
   "source": [
    "#### [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer)\n",
    "\n",
    "- Bins continuous data into intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715344a-88e2-44c6-be99-fe3abb29e6ce",
   "metadata": {},
   "source": [
    "**example: discretize `flipper_length_mm`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ca45ae5e-0cfc-49d8-ac85-dce89efb2307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "297222d0-7300-4243-b1f6-5009a9a7b00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(\n",
    "    n_bins=3,\n",
    "    encode='onehot-dense',\n",
    "    strategy='quantile'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea149ec-c91c-4a3e-af60-2c9eea8af811",
   "metadata": {},
   "source": [
    "- The following line of code will result in `ValueError`\n",
    "- Read the error message and try to fix the bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ee995e4a-ad3c-408f-9be1-afd7debf043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  kbins.fit(X_train[['flipper_length_mm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b3dc8-4fda-454f-9921-af25637e2868",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Hint**\n",
    "- Try `X_train.isna().sum()` to see if there are missing values in numerical columns\n",
    "- If yes, impute the missing values, say the way it was done in notebook _1_intro_to_fe_\n",
    "- Then run the above code again, and proceed to the `.transform()` step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "knn_imputer.fit(X_train[['flipper_length_mm']])\n",
    "\n",
    "X_train['flipper_length_mm'] = knn_imputer.transform(\n",
    "    X_train[['flipper_length_mm']]\n",
    ").flatten()\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(\n",
    "    n_bins=3,\n",
    "    encode='onehot-dense',\n",
    "    strategy='quantile'\n",
    ")\n",
    "\n",
    "kbins.fit(X_train[['flipper_length_mm']])\n",
    "t = kbins.transform(X_train[['flipper_length_mm']])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "abfa8742-cb4c-4d8d-bf8c-7fe7f8837c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_flipper: 172.0 - 192.0\n",
      "medium_flipper: 192.0 - 210.0\n",
      "large_flipper: 210.0 - 230.0\n"
     ]
    }
   ],
   "source": [
    "# Fit the KBinsDiscretizer on the 'flipper_length_mm' column of the training data\n",
    "kbins.fit(X_train[['flipper_length_mm']])\n",
    "\n",
    "# Transform the 'flipper_length_mm' values into binned categories\n",
    "t = kbins.transform(X_train[['flipper_length_mm']])\n",
    "\n",
    "# Display the shape of the transformed data (number of rows, number of bins)\n",
    "t.shape   # BONUS: see bin ranges\n",
    "\n",
    "# Define human-readable bin names for the different categories of 'flipper_length_mm'\n",
    "bin_names = ['small_flipper', 'medium_flipper', 'large_flipper']\n",
    "\n",
    "# Retrieve the bin edges (ranges) and round them to one decimal place\n",
    "edges = kbins.bin_edges_[0].round(1)\n",
    "\n",
    "# Loop through each bin and print the bin name along with its corresponding range\n",
    "for i in range(len(bin_names)):\n",
    "    print(f\"{bin_names[i]}: {edges[i]} - {edges[i+1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654aed67-b335-4192-a781-f6ab0b089ad3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84b447-2ecb-4147-bf6a-3035f425068b",
   "metadata": {},
   "source": [
    "**With `KBinsDiscretizer` what does the following hyperparameter choices mean?**\n",
    "- `n_bins=3`,\n",
    "- `encode='onehot-dense'`,\n",
    "- `strategy='quantile'`?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
